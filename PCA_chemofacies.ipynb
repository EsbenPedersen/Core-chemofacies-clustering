{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd #dataframe features\n",
    "\n",
    "from sklearn import decomposition\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "#from adjustText import adjust_text ##need to incorporate this from Github\n",
    "\n",
    "#%reset how else do you clear variables?\n",
    "#import csv files from core. A lot of room for improvement here.\n",
    "dataimport = r'C:\\Users\\larsont\\Desktop\\Coredatabase\\RandomCore.csv'\n",
    "LOD_T5 = r'C:\\Users\\larsont\\Desktop\\Coredatabase\\T5iLOD.csv'\n",
    "#convert imported files to dataframes. The idea is to not change the original files\n",
    "coredata = pd.read_csv(dataimport)\n",
    "LODT5=pd.read_csv(LOD_T5)\n",
    "coredata.sort_values(by=['Depth_calculated']) #sorts coredata by depth\n",
    "elements = ['Na', 'Mg', 'Al', 'Si', 'P', 'S', 'K', 'Ca', 'Ti','Mn', 'Fe', 'Ba', 'V', 'Cr', 'Co', 'Ni', 'Cu', 'Zn', 'Ga', 'As', 'Pb','Se', 'Th', 'Rb', 'U', 'Sr', 'Y', 'Zr', 'Nb', 'Mo']\n",
    "\n",
    "coredata[elements]=np.maximum(coredata[elements],LODT5) #add LOD to each element\n",
    "\n",
    "# vector of the outlier values for each element\n",
    "Element_outlier=(coredata[elements]).mean()+4*(coredata[elements]).std()#toggle 3 or 4 to decide if enough outliers are selected\n",
    "coredata['Outliers']=((coredata[elements])>Element_outlier).any(axis='columns') #makes a new column based on above conditional format\n",
    "\n",
    "\n",
    "fig, ((ax1, ax2, ax3)) = plt.subplots(nrows=1, ncols=3, sharex=True, sharey=True, figsize=(15,5))\n",
    "plt.subplot(1, 3, 1)\n",
    "groups = coredata.groupby(\"Outliers\")\n",
    "for name, group in groups:\n",
    "    plt.plot(group[\"Al\"], group[\"Si\"], marker=\"o\",  ms=4, linestyle=\"\", label=name)\n",
    "plt.title('Outliers')\n",
    "plt.xlabel('Aluminum %')\n",
    "plt.ylabel('Silicon %')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.subplot(1, 3,2)\n",
    "groups = coredata.groupby(\"Outliers\")\n",
    "for name, group in groups:\n",
    "    plt.plot(group[\"Ca\"], group[\"Sr\"], marker=\"o\",  ms=4, linestyle=\"\", label=name)\n",
    "plt.title('Outliers')\n",
    "plt.xlabel('Calcium %')\n",
    "plt.ylabel('Strontium %')\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "#Principal Component Analysis\n",
    "pca = decomposition.PCA(n_components=len(elements))#toggle n_components\n",
    "# Centered (mean = zero X - X.mean(axis=0)) and with unit variance\n",
    "X=coredata \n",
    "y = coredata.Outliers.values\n",
    "X = X[elements].values\n",
    "X_centered = StandardScaler().fit(X).transform(X)\n",
    "pca.fit(X_centered)\n",
    "X_pca = pca.transform(X_centered)\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(X_pca[y == False, 0], X_pca[y == False, 1],marker=\"o\", label='Outlier', ms=4, linestyle=\"\")\n",
    "plt.plot(X_pca[y == True, 0], X_pca[y == True, 1], marker=\"o\", label='Sample', ms=4, linestyle=\"\")\n",
    "\n",
    "plt.title('PCA')\n",
    "plt.xlabel('PC-1')\n",
    "plt.ylabel('PC-2')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=(coredata[coredata['Outliers'] == False]) #excludes outliers\n",
    "#X=coredata \n",
    "\n",
    "x = X[elements].values #all elements\n",
    "#y = coredata.Outliers.\n",
    "\n",
    "# In general, it's a good idea to scale the data prior to PCA.\n",
    "\n",
    "scaler = StandardScaler() #create a standard scaler object\n",
    "pca = PCA() #create a PCA object called pca. could include pca = PCA(n_components=1)\n",
    "\n",
    "scaler.fit(x)\n",
    "#X=scaler.transform(X)    \n",
    "x_new = pca.fit_transform(scaler.transform(x))\n",
    "#print(scaler.transform(X))\n",
    "features= np.arange(len(elements))\n",
    "\n",
    "#Call the function. Use only the 2 PCs.\n",
    "#myplot(x_new[:,0:2],np.transpose(pca.components_[0:2, :]))\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ((ax4, ax5)) = plt.subplots(nrows=1, ncols=2, sharex=True, sharey=True, figsize=(10,5))\n",
    "plt.subplot(1, 2, 1)\n",
    "\n",
    "plt.plot(pca.explained_variance_ratio_.cumsum(),marker='o',linestyle='--')\n",
    "plt.ylabel('cumulative explained variance')\n",
    "plt.xlabel('PCA features')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.bar(features,pca.explained_variance_ratio_, color='black')\n",
    "plt.xlabel('PCA features')\n",
    "plt.ylabel('variance %')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### select the number of clusters and number of PC's used in the clustering. \n",
    "#Esben added computations that optimize the number of PC's and the number of cluster.\n",
    "clusters=5\n",
    "Principal_components=5\n",
    "\n",
    "x_cluster = x_new[:, np.arange(Principal_components)] #select the PCAs to use for clustering.\n",
    "kmeans = KMeans(n_clusters=clusters)#select the number of clusters\n",
    "kmeans.fit(x_cluster) #results from PCA\n",
    "y_kmeans = kmeans.predict(x_cluster)\n",
    "\n",
    "def myplot(score,coeff,labels=elements): #Esben puts labels = None \n",
    "    \n",
    "    xs = score[:,0]\n",
    "    ys = score[:,1]\n",
    "    n = coeff.shape[0]\n",
    "    scalex = 1.0/(xs.max() - xs.min())\n",
    "    scaley = 1.0/(ys.max() - ys.min())\n",
    "\n",
    "    plt.scatter(xs * scalex,ys * scaley,s=3.5,c=y_kmeans,cmap='viridis') #clustered. c='tab:blue' to not cluster\n",
    "    for i in range(n):\n",
    "        plt.arrow(0, 0, coeff[i,0]*2, coeff[i,1]*2, color = 'k', linewidth = 0.25,alpha = None,length_includes_head=True,\n",
    "                  head_width=0.05, head_length=0.05) #I added multipliers to increase lenght of vector\n",
    "        plt.text(coeff[i,0]* 2.75, coeff[i,1] * 2.75, labels[i], color = 'k', ha = 'center', va = 'center')    \n",
    "    \n",
    "    plt.xlim(-1,1)\n",
    "    plt.ylim(-1,1)\n",
    "    plt.xlabel(\"PC{}\".format(1))\n",
    "    plt.ylabel(\"PC{}\".format(2))\n",
    "    #plt.grid()\n",
    "\n",
    "\n",
    "fig, ((ax6, ax7)) = plt.subplots(nrows=1, ncols=2, sharex=True, sharey=True, figsize=(10,5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(x_cluster[:, 0], x_cluster[:, 1], c=y_kmeans, s=10, cmap='viridis')\n",
    "centers = kmeans.cluster_centers_\n",
    "\n",
    "plt.scatter(centers[:, 0], centers[:, 1],marker='x', c='black', s=200);\n",
    "plt.xlabel('PC-1')\n",
    "plt.ylabel('PC-2')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "#Call the function. Use only the 2 PCs.\n",
    "myplot(x_new[:,0:2],np.transpose(pca.components_[0:2, :]))\n",
    "plt.tight_layout()\n",
    "#adjust_text(texts, only_move='y', arrowprops=dict(arrowstyle=\"->\", color='r', lw=0.5)) #this will adjust text\n",
    "\n",
    "plt.show()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Chemofacies=y_kmeans\n",
    "X['Chemofacies']=Chemofacies #makes a new column based on above conditional format\n",
    "\n",
    "Y=(coredata[coredata['Outliers'] == True]) #excludes outliers\n",
    "Y[\"Chemofacies\"] = np.nan\n",
    "\n",
    "Z=pd.concat([X, Y], ignore_index=True)\n",
    "\n",
    "Z.to_csv (r'C:\\Users\\larsont\\Desktop\\Coredatabase\\Z.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
